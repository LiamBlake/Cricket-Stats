{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pandas import read_csv\n",
    "from random import shuffle\n",
    "from math import floor\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = plt.rcParams['axes.prop_cycle'].by_key()['color']\n",
    "\n",
    "\n",
    "def plot_roc(name, labels, predictions, **kwargs):\n",
    "    fp, tp, _ = sklearn.metrics.roc_curve(labels, predictions)\n",
    "\n",
    "    plt.plot(100*fp, 100*tp, label=name, linewidth=2, **kwargs)\n",
    "    plt.xlabel('False positives [%]')\n",
    "    plt.ylabel('True positives [%]')\n",
    "    plt.xlim([-0.5,20])\n",
    "    plt.ylim([80,100.5])\n",
    "    plt.grid(True)\n",
    "    ax = plt.gca()\n",
    "    ax.set_aspect('equal')\n",
    "\n",
    "METRICS = [\n",
    "    keras.metrics.TruePositives(name='tp'),\n",
    "    keras.metrics.FalsePositives(name='fp'),\n",
    "    keras.metrics.TrueNegatives(name='tn'),\n",
    "    keras.metrics.FalseNegatives(name='fn'), \n",
    "    keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "    keras.metrics.Precision(name='precision'),\n",
    "    keras.metrics.Recall(name='recall'),\n",
    "    keras.metrics.AUC(name='auc'),\n",
    "    keras.metrics.AUC(name='prc', curve='PR'), # precision-recall curve\n",
    "]\n",
    "\n",
    "def plot_metrics(history):\n",
    "    metrics = ['loss', 'prc', 'precision', 'recall']\n",
    "    for n, metric in enumerate(metrics):\n",
    "        name = metric.replace(\"_\",\" \").capitalize()\n",
    "        plt.subplot(2,2,n+1)\n",
    "        plt.plot(history.epoch, history.history[metric], color=colors[0], label='Train')\n",
    "        plt.plot(history.epoch, history.history['val_'+metric],\n",
    "                 color=colors[0], linestyle=\"--\", label='Val')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel(name)\n",
    "        if metric == 'loss':\n",
    "            plt.ylim([0, plt.ylim()[1]])\n",
    "        elif metric == 'auc':\n",
    "            plt.ylim([0.8,1])\n",
    "        else:\n",
    "            plt.ylim([0,1])\n",
    "\n",
    "    plt.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, X_test, Y_test):\n",
    "    test_preds = model.predict(X_test)\n",
    "\n",
    "    test_W = model.predict(X_test[(Y_test == 1).reshape((X_test.shape[0],))])\n",
    "    test_no = model.predict(X_test[(Y_test == 0).reshape((X_test.shape[0],))])\n",
    "\n",
    "    print(\"====All====\")\n",
    "    for name, value in zip(model.metrics_names, test_preds):\n",
    "        print(name, ': ', value)\n",
    "    print()\n",
    "\n",
    "    print(\"====Wickets only====\")\n",
    "    for name, value in zip(model.metrics_names, test_W):\n",
    "        print(name, ': ', value)\n",
    "    print()\n",
    "\n",
    "    print(\"====NOs only====\")\n",
    "    for name, value in zip(model.metrics_names, test_no):\n",
    "        print(name, ': ', value)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "X = read_csv(\"data/fow_ann_X.csv\").to_numpy()\n",
    "Y = read_csv(\"data/fow_ann_Y.csv\").to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into training, testing, validation\n",
    "n_rows = X.shape[0]\n",
    "shuffle_idx = list(range(n_rows))\n",
    "shuffle(shuffle_idx)\n",
    "\n",
    "X = X[shuffle_idx, :]\n",
    "Y = Y[shuffle_idx, :]\n",
    "\n",
    "split = (0.8, 0.1, 0.1)\n",
    "split_idx = (floor(split[0]*n_rows) - 1, floor((split[0] + split[1])*n_rows) - 1)\n",
    "X_train = X[0:split_idx[0],:]\n",
    "Y_train = Y[0:split_idx[0],:]\n",
    "X_val = X[split_idx[0]+1:split_idx[1],:]\n",
    "Y_val = Y[split_idx[0]+1:split_idx[1],:]\n",
    "X_test = X[split_idx[1]+1:,:]\n",
    "Y_test = Y[split_idx[1]+1:,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline Model - Proportions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PropModel:\n",
    "    def __init__(self, Y, metrics):\n",
    "        self.Wprop = np.sum(Y)/(Y.shape[0])\n",
    "        self.metrics_names = metrics\n",
    "    \n",
    "    def predict(self, X, **kwargs):\n",
    "        return self.Wprop * np.ones(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "prop_model = PropModel(Y_train, METRICS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====All====\n",
      "<tensorflow.python.keras.metrics.TruePositives object at 0x000001EBEF0DE188> :  [0.01640188 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188\n",
      " 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188\n",
      " 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188\n",
      " 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188\n",
      " 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188\n",
      " 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188\n",
      " 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188\n",
      " 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188\n",
      " 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188\n",
      " 0.01640188 0.01640188 0.01640188]\n",
      "<tensorflow.python.keras.metrics.FalsePositives object at 0x000001EBEF104548> :  [0.01640188 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188\n",
      " 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188\n",
      " 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188\n",
      " 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188\n",
      " 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188\n",
      " 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188\n",
      " 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188\n",
      " 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188\n",
      " 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188\n",
      " 0.01640188 0.01640188 0.01640188]\n",
      "<tensorflow.python.keras.metrics.TrueNegatives object at 0x000001EBEF11F308> :  [0.01640188 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188\n",
      " 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188\n",
      " 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188\n",
      " 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188\n",
      " 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188\n",
      " 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188\n",
      " 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188\n",
      " 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188\n",
      " 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188\n",
      " 0.01640188 0.01640188 0.01640188]\n",
      "<tensorflow.python.keras.metrics.FalseNegatives object at 0x000001EBEF11FC88> :  [0.01640188 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188\n",
      " 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188\n",
      " 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188\n",
      " 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188\n",
      " 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188\n",
      " 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188\n",
      " 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188\n",
      " 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188\n",
      " 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188\n",
      " 0.01640188 0.01640188 0.01640188]\n",
      "<tensorflow.python.keras.metrics.BinaryAccuracy object at 0x000001EBEF157508> :  [0.01640188 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188\n",
      " 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188\n",
      " 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188\n",
      " 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188\n",
      " 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188\n",
      " 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188\n",
      " 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188\n",
      " 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188\n",
      " 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188\n",
      " 0.01640188 0.01640188 0.01640188]\n",
      "<tensorflow.python.keras.metrics.Precision object at 0x000001EBEF15F388> :  [0.01640188 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188\n",
      " 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188\n",
      " 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188\n",
      " 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188\n",
      " 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188\n",
      " 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188\n",
      " 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188\n",
      " 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188\n",
      " 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188\n",
      " 0.01640188 0.01640188 0.01640188]\n",
      "<tensorflow.python.keras.metrics.Recall object at 0x000001EBEF15FC48> :  [0.01640188 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188\n",
      " 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188\n",
      " 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188\n",
      " 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188\n",
      " 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188\n",
      " 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188\n",
      " 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188\n",
      " 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188\n",
      " 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188\n",
      " 0.01640188 0.01640188 0.01640188]\n",
      "<tensorflow.python.keras.metrics.AUC object at 0x000001EBEF16A688> :  [0.01640188 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188\n",
      " 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188\n",
      " 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188\n",
      " 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188\n",
      " 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188\n",
      " 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188\n",
      " 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188\n",
      " 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188\n",
      " 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188\n",
      " 0.01640188 0.01640188 0.01640188]\n",
      "<tensorflow.python.keras.metrics.AUC object at 0x000001EBEF16AC08> :  [0.01640188 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188\n",
      " 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188\n",
      " 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188\n",
      " 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188\n",
      " 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188\n",
      " 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188\n",
      " 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188\n",
      " 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188\n",
      " 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188\n",
      " 0.01640188 0.01640188 0.01640188]\n",
      "\n",
      "====Wickets only====\n",
      "<tensorflow.python.keras.metrics.TruePositives object at 0x000001EBEF0DE188> :  [0.01640188 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188\n",
      " 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188\n",
      " 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188\n",
      " 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188\n",
      " 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188\n",
      " 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188\n",
      " 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188\n",
      " 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188\n",
      " 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188\n",
      " 0.01640188 0.01640188 0.01640188]\n",
      "<tensorflow.python.keras.metrics.FalsePositives object at 0x000001EBEF104548> :  [0.01640188 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188\n",
      " 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188\n",
      " 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188\n",
      " 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188\n",
      " 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188\n",
      " 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188\n",
      " 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188\n",
      " 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188\n",
      " 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188\n",
      " 0.01640188 0.01640188 0.01640188]\n",
      "<tensorflow.python.keras.metrics.TrueNegatives object at 0x000001EBEF11F308> :  [0.01640188 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188\n",
      " 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188\n",
      " 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188\n",
      " 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188\n",
      " 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188\n",
      " 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188\n",
      " 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188\n",
      " 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188\n",
      " 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188\n",
      " 0.01640188 0.01640188 0.01640188]\n",
      "<tensorflow.python.keras.metrics.FalseNegatives object at 0x000001EBEF11FC88> :  [0.01640188 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188\n",
      " 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188\n",
      " 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188\n",
      " 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188\n",
      " 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188\n",
      " 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188\n",
      " 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188\n",
      " 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188\n",
      " 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188\n",
      " 0.01640188 0.01640188 0.01640188]\n",
      "<tensorflow.python.keras.metrics.BinaryAccuracy object at 0x000001EBEF157508> :  [0.01640188 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188\n",
      " 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188\n",
      " 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188\n",
      " 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188\n",
      " 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188\n",
      " 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188\n",
      " 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188\n",
      " 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188\n",
      " 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188\n",
      " 0.01640188 0.01640188 0.01640188]\n",
      "<tensorflow.python.keras.metrics.Precision object at 0x000001EBEF15F388> :  [0.01640188 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188\n",
      " 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188\n",
      " 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188\n",
      " 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188\n",
      " 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188\n",
      " 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188\n",
      " 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188\n",
      " 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188\n",
      " 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188\n",
      " 0.01640188 0.01640188 0.01640188]\n",
      "<tensorflow.python.keras.metrics.Recall object at 0x000001EBEF15FC48> :  [0.01640188 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188\n",
      " 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188\n",
      " 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188\n",
      " 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188\n",
      " 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188\n",
      " 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188\n",
      " 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188\n",
      " 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188\n",
      " 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188\n",
      " 0.01640188 0.01640188 0.01640188]\n",
      "<tensorflow.python.keras.metrics.AUC object at 0x000001EBEF16A688> :  [0.01640188 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188\n",
      " 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188\n",
      " 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188\n",
      " 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188\n",
      " 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188\n",
      " 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188\n",
      " 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188\n",
      " 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188\n",
      " 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188\n",
      " 0.01640188 0.01640188 0.01640188]\n",
      "<tensorflow.python.keras.metrics.AUC object at 0x000001EBEF16AC08> :  [0.01640188 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188\n",
      " 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188\n",
      " 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188\n",
      " 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188\n",
      " 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188\n",
      " 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188\n",
      " 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188\n",
      " 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188\n",
      " 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188\n",
      " 0.01640188 0.01640188 0.01640188]\n",
      "\n",
      "====NOs only====\n",
      "<tensorflow.python.keras.metrics.TruePositives object at 0x000001EBEF0DE188> :  [0.01640188 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188\n",
      " 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188\n",
      " 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188\n",
      " 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188\n",
      " 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188\n",
      " 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188\n",
      " 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188\n",
      " 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188\n",
      " 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188\n",
      " 0.01640188 0.01640188 0.01640188]\n",
      "<tensorflow.python.keras.metrics.FalsePositives object at 0x000001EBEF104548> :  [0.01640188 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188\n",
      " 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188\n",
      " 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188\n",
      " 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188\n",
      " 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188\n",
      " 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188\n",
      " 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188\n",
      " 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188\n",
      " 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188\n",
      " 0.01640188 0.01640188 0.01640188]\n",
      "<tensorflow.python.keras.metrics.TrueNegatives object at 0x000001EBEF11F308> :  [0.01640188 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188\n",
      " 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188\n",
      " 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188\n",
      " 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188\n",
      " 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188\n",
      " 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188\n",
      " 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188\n",
      " 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188\n",
      " 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188\n",
      " 0.01640188 0.01640188 0.01640188]\n",
      "<tensorflow.python.keras.metrics.FalseNegatives object at 0x000001EBEF11FC88> :  [0.01640188 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188\n",
      " 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188\n",
      " 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188\n",
      " 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188\n",
      " 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188\n",
      " 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188\n",
      " 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188\n",
      " 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188\n",
      " 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188\n",
      " 0.01640188 0.01640188 0.01640188]\n",
      "<tensorflow.python.keras.metrics.BinaryAccuracy object at 0x000001EBEF157508> :  [0.01640188 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188\n",
      " 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188\n",
      " 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188\n",
      " 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188\n",
      " 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188\n",
      " 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188\n",
      " 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188\n",
      " 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188\n",
      " 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188\n",
      " 0.01640188 0.01640188 0.01640188]\n",
      "<tensorflow.python.keras.metrics.Precision object at 0x000001EBEF15F388> :  [0.01640188 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188\n",
      " 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188\n",
      " 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188\n",
      " 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188\n",
      " 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188\n",
      " 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188\n",
      " 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188\n",
      " 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188\n",
      " 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188\n",
      " 0.01640188 0.01640188 0.01640188]\n",
      "<tensorflow.python.keras.metrics.Recall object at 0x000001EBEF15FC48> :  [0.01640188 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188\n",
      " 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188\n",
      " 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188\n",
      " 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188\n",
      " 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188\n",
      " 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188\n",
      " 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188\n",
      " 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188\n",
      " 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188\n",
      " 0.01640188 0.01640188 0.01640188]\n",
      "<tensorflow.python.keras.metrics.AUC object at 0x000001EBEF16A688> :  [0.01640188 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188\n",
      " 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188\n",
      " 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188\n",
      " 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188\n",
      " 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188\n",
      " 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188\n",
      " 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188\n",
      " 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188\n",
      " 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188\n",
      " 0.01640188 0.01640188 0.01640188]\n",
      "<tensorflow.python.keras.metrics.AUC object at 0x000001EBEF16AC08> :  [0.01640188 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188\n",
      " 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188\n",
      " 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188\n",
      " 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188\n",
      " 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188\n",
      " 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188\n",
      " 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188\n",
      " 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188\n",
      " 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188 0.01640188\n",
      " 0.01640188 0.01640188 0.01640188]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate\n",
    "evaluate_model(prop_model, X_test, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "nW = np.sum(Y_train)\n",
    "nno = Y.shape[0] - nW\n",
    "initial_bias = np.log([nW/nno])\n",
    "output_bias = keras.initializers.Constant(initial_bias)\n",
    "\n",
    "total = nW + nno\n",
    "weight_for_0 = (1 / nno)*(total)/2.0 \n",
    "weight_for_1 = (1 / nW)*(total)/2.0\n",
    "class_weight = {0: weight_for_0, 1: weight_for_1}\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(64, input_dim=X.shape[1], activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid', bias_initializer=output_bias))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=METRICS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "10590/10590 [==============================] - 15s 1ms/step - loss: 0.8185 - tp: 7346.0000 - fp: 424585.0000 - tn: 242049.0000 - fn: 3747.0000 - accuracy: 0.3680 - precision: 0.0170 - recall: 0.6622 - auc: 0.5315 - prc: 0.0189 - val_loss: 0.6642 - val_tp: 678.0000 - val_fp: 29057.0000 - val_tn: 54209.0000 - val_fn: 771.0000 - val_accuracy: 0.6479 - val_precision: 0.0228 - val_recall: 0.4679 - val_auc: 0.5775 - val_prc: 0.0238\n",
      "Epoch 2/50\n",
      "10590/10590 [==============================] - 14s 1ms/step - loss: 0.8117 - tp: 8199.0000 - fp: 462798.0000 - tn: 203836.0000 - fn: 2894.0000 - accuracy: 0.3129 - precision: 0.0174 - recall: 0.7391 - auc: 0.5513 - prc: 0.0212 - val_loss: 0.8389 - val_tp: 1295.0000 - val_fp: 75265.0000 - val_tn: 8001.0000 - val_fn: 154.0000 - val_accuracy: 0.1097 - val_precision: 0.0169 - val_recall: 0.8937 - val_auc: 0.5345 - val_prc: 0.0194\n",
      "Epoch 3/50\n",
      "10590/10590 [==============================] - 14s 1ms/step - loss: 0.7899 - tp: 7165.0000 - fp: 424049.0000 - tn: 242585.0000 - fn: 3928.0000 - accuracy: 0.3685 - precision: 0.0166 - recall: 0.6459 - auc: 0.5176 - prc: 0.0185 - val_loss: 0.9306 - val_tp: 1352.0000 - val_fp: 79867.0000 - val_tn: 3399.0000 - val_fn: 97.0000 - val_accuracy: 0.0561 - val_precision: 0.0166 - val_recall: 0.9331 - val_auc: 0.4777 - val_prc: 0.0171\n",
      "Epoch 4/50\n",
      "10590/10590 [==============================] - 14s 1ms/step - loss: 0.7816 - tp: 7448.0000 - fp: 426359.0000 - tn: 240275.0000 - fn: 3645.0000 - accuracy: 0.3655 - precision: 0.0172 - recall: 0.6714 - auc: 0.5325 - prc: 0.0195 - val_loss: 0.8052 - val_tp: 1299.0000 - val_fp: 77281.0000 - val_tn: 5985.0000 - val_fn: 150.0000 - val_accuracy: 0.0860 - val_precision: 0.0165 - val_recall: 0.8965 - val_auc: 0.5544 - val_prc: 0.0229\n",
      "Epoch 5/50\n",
      "10590/10590 [==============================] - 14s 1ms/step - loss: 0.7730 - tp: 7331.0000 - fp: 406211.0000 - tn: 260423.0000 - fn: 3762.0000 - accuracy: 0.3951 - precision: 0.0177 - recall: 0.6609 - auc: 0.5469 - prc: 0.0206 - val_loss: 0.7257 - val_tp: 948.0000 - val_fp: 47347.0000 - val_tn: 35919.0000 - val_fn: 501.0000 - val_accuracy: 0.4352 - val_precision: 0.0196 - val_recall: 0.6542 - val_auc: 0.5797 - val_prc: 0.0249\n",
      "Epoch 6/50\n",
      "10590/10590 [==============================] - 13s 1ms/step - loss: 0.7762 - tp: 7307.0000 - fp: 405231.0000 - tn: 261403.0000 - fn: 3786.0000 - accuracy: 0.3965 - precision: 0.0177 - recall: 0.6587 - auc: 0.5479 - prc: 0.0209 - val_loss: 0.6248 - val_tp: 309.0000 - val_fp: 10441.0000 - val_tn: 72825.0000 - val_fn: 1140.0000 - val_accuracy: 0.8633 - val_precision: 0.0287 - val_recall: 0.2133 - val_auc: 0.5615 - val_prc: 0.0226\n",
      "Epoch 7/50\n",
      "10590/10590 [==============================] - 13s 1ms/step - loss: 0.7874 - tp: 8052.0000 - fp: 486320.0000 - tn: 180314.0000 - fn: 3041.0000 - accuracy: 0.2779 - precision: 0.0163 - recall: 0.7259 - auc: 0.4998 - prc: 0.0166 - val_loss: 0.7937 - val_tp: 1449.0000 - val_fp: 83266.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.0171 - val_precision: 0.0171 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.0171\n",
      "Epoch 8/50\n",
      "10590/10590 [==============================] - 12s 1ms/step - loss: 0.7718 - tp: 11093.0000 - fp: 666634.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 0.0164 - precision: 0.0164 - recall: 1.0000 - auc: 0.4954 - prc: 0.0162 - val_loss: 0.7989 - val_tp: 1449.0000 - val_fp: 83266.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.0171 - val_precision: 0.0171 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.0171\n",
      "Epoch 9/50\n",
      "10590/10590 [==============================] - 12s 1ms/step - loss: 0.7717 - tp: 11093.0000 - fp: 666634.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 0.0164 - precision: 0.0164 - recall: 1.0000 - auc: 0.4940 - prc: 0.0161 - val_loss: 0.7864 - val_tp: 1449.0000 - val_fp: 83266.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.0171 - val_precision: 0.0171 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.0171\n",
      "Epoch 10/50\n",
      "10590/10590 [==============================] - 12s 1ms/step - loss: 0.7718 - tp: 11093.0000 - fp: 666634.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 0.0164 - precision: 0.0164 - recall: 1.0000 - auc: 0.4992 - prc: 0.0164 - val_loss: 0.8056 - val_tp: 1449.0000 - val_fp: 83266.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.0171 - val_precision: 0.0171 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.0171\n",
      "Epoch 11/50\n",
      "10590/10590 [==============================] - 12s 1ms/step - loss: 0.7717 - tp: 11093.0000 - fp: 666634.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 0.0164 - precision: 0.0164 - recall: 1.0000 - auc: 0.4984 - prc: 0.0163 - val_loss: 0.7866 - val_tp: 1449.0000 - val_fp: 83266.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.0171 - val_precision: 0.0171 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.0171\n",
      "Epoch 12/50\n",
      "10590/10590 [==============================] - 12s 1ms/step - loss: 0.7718 - tp: 11093.0000 - fp: 666634.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 0.0164 - precision: 0.0164 - recall: 1.0000 - auc: 0.4984 - prc: 0.0162 - val_loss: 0.7915 - val_tp: 1449.0000 - val_fp: 83266.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.0171 - val_precision: 0.0171 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.0171\n",
      "Epoch 13/50\n",
      "10590/10590 [==============================] - 13s 1ms/step - loss: 0.7717 - tp: 11093.0000 - fp: 666634.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 0.0164 - precision: 0.0164 - recall: 1.0000 - auc: 0.4959 - prc: 0.0161 - val_loss: 0.7792 - val_tp: 1449.0000 - val_fp: 83266.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.0171 - val_precision: 0.0171 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.0171\n",
      "Epoch 14/50\n",
      "10590/10590 [==============================] - 13s 1ms/step - loss: 0.7718 - tp: 11093.0000 - fp: 666634.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 0.0164 - precision: 0.0164 - recall: 1.0000 - auc: 0.4980 - prc: 0.0162 - val_loss: 0.7984 - val_tp: 1449.0000 - val_fp: 83266.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.0171 - val_precision: 0.0171 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.0171\n",
      "Epoch 15/50\n",
      "10590/10590 [==============================] - 13s 1ms/step - loss: 0.7717 - tp: 11093.0000 - fp: 666634.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 0.0164 - precision: 0.0164 - recall: 1.0000 - auc: 0.4969 - prc: 0.0162 - val_loss: 0.7856 - val_tp: 1449.0000 - val_fp: 83266.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.0171 - val_precision: 0.0171 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.0171\n",
      "Epoch 16/50\n",
      "10590/10590 [==============================] - 13s 1ms/step - loss: 0.7717 - tp: 11093.0000 - fp: 666634.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 0.0164 - precision: 0.0164 - recall: 1.0000 - auc: 0.5019 - prc: 0.0164 - val_loss: 0.7952 - val_tp: 1449.0000 - val_fp: 83266.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.0171 - val_precision: 0.0171 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.0171\n",
      "Epoch 17/50\n",
      "10590/10590 [==============================] - 13s 1ms/step - loss: 0.7718 - tp: 11093.0000 - fp: 666634.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 0.0164 - precision: 0.0164 - recall: 1.0000 - auc: 0.4946 - prc: 0.0161 - val_loss: 0.7985 - val_tp: 1449.0000 - val_fp: 83266.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.0171 - val_precision: 0.0171 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.0171\n",
      "Epoch 18/50\n",
      "10590/10590 [==============================] - 12s 1ms/step - loss: 0.7717 - tp: 11093.0000 - fp: 666634.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 0.0164 - precision: 0.0164 - recall: 1.0000 - auc: 0.5010 - prc: 0.0163 - val_loss: 0.7830 - val_tp: 1449.0000 - val_fp: 83266.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.0171 - val_precision: 0.0171 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.0171\n",
      "Epoch 19/50\n",
      "10590/10590 [==============================] - 13s 1ms/step - loss: 0.7718 - tp: 11093.0000 - fp: 666634.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 0.0164 - precision: 0.0164 - recall: 1.0000 - auc: 0.5010 - prc: 0.0163 - val_loss: 0.8107 - val_tp: 1449.0000 - val_fp: 83266.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.0171 - val_precision: 0.0171 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.0171\n",
      "Epoch 20/50\n",
      "10590/10590 [==============================] - 13s 1ms/step - loss: 0.7718 - tp: 11093.0000 - fp: 666634.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 0.0164 - precision: 0.0164 - recall: 1.0000 - auc: 0.5019 - prc: 0.0164 - val_loss: 0.8070 - val_tp: 1449.0000 - val_fp: 83266.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.0171 - val_precision: 0.0171 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.0171\n",
      "Epoch 21/50\n",
      "10590/10590 [==============================] - 13s 1ms/step - loss: 0.7717 - tp: 11093.0000 - fp: 666634.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 0.0164 - precision: 0.0164 - recall: 1.0000 - auc: 0.4954 - prc: 0.0161 - val_loss: 0.7805 - val_tp: 1449.0000 - val_fp: 83266.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.0171 - val_precision: 0.0171 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.0171\n",
      "Epoch 22/50\n",
      "10590/10590 [==============================] - 13s 1ms/step - loss: 0.7717 - tp: 11093.0000 - fp: 666634.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 0.0164 - precision: 0.0164 - recall: 1.0000 - auc: 0.5006 - prc: 0.0163 - val_loss: 0.7911 - val_tp: 1449.0000 - val_fp: 83266.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.0171 - val_precision: 0.0171 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.0171\n",
      "Epoch 23/50\n",
      "10590/10590 [==============================] - 13s 1ms/step - loss: 0.7717 - tp: 11093.0000 - fp: 666634.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 0.0164 - precision: 0.0164 - recall: 1.0000 - auc: 0.4979 - prc: 0.0162 - val_loss: 0.7987 - val_tp: 1449.0000 - val_fp: 83266.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.0171 - val_precision: 0.0171 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.0171\n",
      "Epoch 24/50\n",
      "10590/10590 [==============================] - 13s 1ms/step - loss: 0.7717 - tp: 11093.0000 - fp: 666634.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 0.0164 - precision: 0.0164 - recall: 1.0000 - auc: 0.5017 - prc: 0.0164 - val_loss: 0.7747 - val_tp: 1449.0000 - val_fp: 83266.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.0171 - val_precision: 0.0171 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.0171\n",
      "Epoch 25/50\n",
      "10590/10590 [==============================] - 12s 1ms/step - loss: 0.7718 - tp: 11093.0000 - fp: 666634.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 0.0164 - precision: 0.0164 - recall: 1.0000 - auc: 0.4988 - prc: 0.0163 - val_loss: 0.7973 - val_tp: 1449.0000 - val_fp: 83266.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.0171 - val_precision: 0.0171 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.0171\n",
      "Epoch 26/50\n",
      "10590/10590 [==============================] - 12s 1ms/step - loss: 0.7718 - tp: 11093.0000 - fp: 666634.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 0.0164 - precision: 0.0164 - recall: 1.0000 - auc: 0.4948 - prc: 0.0161 - val_loss: 0.7859 - val_tp: 1449.0000 - val_fp: 83266.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.0171 - val_precision: 0.0171 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.0171\n",
      "Epoch 27/50\n",
      "10590/10590 [==============================] - 12s 1ms/step - loss: 0.7718 - tp: 11093.0000 - fp: 666634.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 0.0164 - precision: 0.0164 - recall: 1.0000 - auc: 0.4996 - prc: 0.0163 - val_loss: 0.7885 - val_tp: 1449.0000 - val_fp: 83266.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.0171 - val_precision: 0.0171 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.0171\n",
      "Epoch 28/50\n",
      "10590/10590 [==============================] - 12s 1ms/step - loss: 0.7718 - tp: 11093.0000 - fp: 666634.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 0.0164 - precision: 0.0164 - recall: 1.0000 - auc: 0.4963 - prc: 0.0161 - val_loss: 0.7827 - val_tp: 1449.0000 - val_fp: 83266.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.0171 - val_precision: 0.0171 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.0171\n",
      "Epoch 29/50\n",
      "10590/10590 [==============================] - 12s 1ms/step - loss: 0.7718 - tp: 11093.0000 - fp: 666634.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 0.0164 - precision: 0.0164 - recall: 1.0000 - auc: 0.4977 - prc: 0.0163 - val_loss: 0.7850 - val_tp: 1449.0000 - val_fp: 83266.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.0171 - val_precision: 0.0171 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.0171\n",
      "Epoch 30/50\n",
      "10590/10590 [==============================] - 12s 1ms/step - loss: 0.7717 - tp: 11093.0000 - fp: 666634.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 0.0164 - precision: 0.0164 - recall: 1.0000 - auc: 0.4979 - prc: 0.0163 - val_loss: 0.7841 - val_tp: 1449.0000 - val_fp: 83266.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.0171 - val_precision: 0.0171 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.0171\n",
      "Epoch 31/50\n",
      "10590/10590 [==============================] - 12s 1ms/step - loss: 0.7717 - tp: 11093.0000 - fp: 666634.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 0.0164 - precision: 0.0164 - recall: 1.0000 - auc: 0.5011 - prc: 0.0164 - val_loss: 0.7880 - val_tp: 1449.0000 - val_fp: 83266.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.0171 - val_precision: 0.0171 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.0171\n",
      "Epoch 32/50\n",
      "10590/10590 [==============================] - 12s 1ms/step - loss: 0.7717 - tp: 11093.0000 - fp: 666634.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 0.0164 - precision: 0.0164 - recall: 1.0000 - auc: 0.4981 - prc: 0.0163 - val_loss: 0.7791 - val_tp: 1449.0000 - val_fp: 83266.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.0171 - val_precision: 0.0171 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.0171\n",
      "Epoch 33/50\n",
      "10590/10590 [==============================] - 12s 1ms/step - loss: 0.7717 - tp: 11093.0000 - fp: 666634.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 0.0164 - precision: 0.0164 - recall: 1.0000 - auc: 0.5017 - prc: 0.0165 - val_loss: 0.7807 - val_tp: 1449.0000 - val_fp: 83266.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.0171 - val_precision: 0.0171 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.0171\n",
      "Epoch 34/50\n",
      "10590/10590 [==============================] - 12s 1ms/step - loss: 0.7718 - tp: 11093.0000 - fp: 666634.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 0.0164 - precision: 0.0164 - recall: 1.0000 - auc: 0.4995 - prc: 0.0163 - val_loss: 0.8001 - val_tp: 1449.0000 - val_fp: 83266.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.0171 - val_precision: 0.0171 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.0171\n",
      "Epoch 35/50\n",
      "10590/10590 [==============================] - 12s 1ms/step - loss: 0.7717 - tp: 11093.0000 - fp: 666634.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 0.0164 - precision: 0.0164 - recall: 1.0000 - auc: 0.4993 - prc: 0.0163 - val_loss: 0.7809 - val_tp: 1449.0000 - val_fp: 83266.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.0171 - val_precision: 0.0171 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.0171\n",
      "Epoch 36/50\n",
      "10590/10590 [==============================] - 12s 1ms/step - loss: 0.7717 - tp: 11093.0000 - fp: 666634.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 0.0164 - precision: 0.0164 - recall: 1.0000 - auc: 0.5033 - prc: 0.0165 - val_loss: 0.7910 - val_tp: 1449.0000 - val_fp: 83266.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.0171 - val_precision: 0.0171 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.0171\n",
      "Epoch 37/50\n",
      "10590/10590 [==============================] - 12s 1ms/step - loss: 0.7718 - tp: 11093.0000 - fp: 666634.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 0.0164 - precision: 0.0164 - recall: 1.0000 - auc: 0.4961 - prc: 0.0161 - val_loss: 0.7878 - val_tp: 1449.0000 - val_fp: 83266.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.0171 - val_precision: 0.0171 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.0171\n",
      "Epoch 38/50\n",
      "10590/10590 [==============================] - 12s 1ms/step - loss: 0.7718 - tp: 11093.0000 - fp: 666634.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 0.0164 - precision: 0.0164 - recall: 1.0000 - auc: 0.4960 - prc: 0.0162 - val_loss: 0.8073 - val_tp: 1449.0000 - val_fp: 83266.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.0171 - val_precision: 0.0171 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.0171\n",
      "Epoch 39/50\n",
      "10590/10590 [==============================] - 13s 1ms/step - loss: 0.7717 - tp: 11093.0000 - fp: 666634.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 0.0164 - precision: 0.0164 - recall: 1.0000 - auc: 0.4975 - prc: 0.0162 - val_loss: 0.7843 - val_tp: 1449.0000 - val_fp: 83266.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.0171 - val_precision: 0.0171 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.0171\n",
      "Epoch 40/50\n",
      "10590/10590 [==============================] - 13s 1ms/step - loss: 0.7718 - tp: 11093.0000 - fp: 666634.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 0.0164 - precision: 0.0164 - recall: 1.0000 - auc: 0.4968 - prc: 0.0162 - val_loss: 0.7721 - val_tp: 1449.0000 - val_fp: 83266.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.0171 - val_precision: 0.0171 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.0171\n",
      "Epoch 41/50\n",
      "10590/10590 [==============================] - 12s 1ms/step - loss: 0.7718 - tp: 11093.0000 - fp: 666634.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 0.0164 - precision: 0.0164 - recall: 1.0000 - auc: 0.4975 - prc: 0.0162 - val_loss: 0.7820 - val_tp: 1449.0000 - val_fp: 83266.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.0171 - val_precision: 0.0171 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.0171\n",
      "Epoch 42/50\n",
      "10590/10590 [==============================] - 12s 1ms/step - loss: 0.7717 - tp: 11093.0000 - fp: 666634.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 0.0164 - precision: 0.0164 - recall: 1.0000 - auc: 0.5006 - prc: 0.0164 - val_loss: 0.7752 - val_tp: 1449.0000 - val_fp: 83266.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.0171 - val_precision: 0.0171 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.0171\n",
      "Epoch 43/50\n",
      "10590/10590 [==============================] - 12s 1ms/step - loss: 0.7718 - tp: 11093.0000 - fp: 666634.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 0.0164 - precision: 0.0164 - recall: 1.0000 - auc: 0.4993 - prc: 0.0163 - val_loss: 0.7999 - val_tp: 1449.0000 - val_fp: 83266.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.0171 - val_precision: 0.0171 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.0171\n",
      "Epoch 44/50\n",
      "10590/10590 [==============================] - 12s 1ms/step - loss: 0.7717 - tp: 11093.0000 - fp: 666634.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 0.0164 - precision: 0.0164 - recall: 1.0000 - auc: 0.5046 - prc: 0.0165 - val_loss: 0.7829 - val_tp: 1449.0000 - val_fp: 83266.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.0171 - val_precision: 0.0171 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.0171\n",
      "Epoch 45/50\n",
      "10590/10590 [==============================] - 12s 1ms/step - loss: 0.7717 - tp: 11093.0000 - fp: 666634.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 0.0164 - precision: 0.0164 - recall: 1.0000 - auc: 0.5012 - prc: 0.0163 - val_loss: 0.7907 - val_tp: 1449.0000 - val_fp: 83266.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.0171 - val_precision: 0.0171 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.0171\n",
      "Epoch 46/50\n",
      "10590/10590 [==============================] - 12s 1ms/step - loss: 0.7717 - tp: 11093.0000 - fp: 666634.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 0.0164 - precision: 0.0164 - recall: 1.0000 - auc: 0.4976 - prc: 0.0161 - val_loss: 0.7898 - val_tp: 1449.0000 - val_fp: 83266.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.0171 - val_precision: 0.0171 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.0171\n",
      "Epoch 47/50\n",
      "10590/10590 [==============================] - 12s 1ms/step - loss: 0.7718 - tp: 11093.0000 - fp: 666634.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 0.0164 - precision: 0.0164 - recall: 1.0000 - auc: 0.4952 - prc: 0.0162 - val_loss: 0.7820 - val_tp: 1449.0000 - val_fp: 83266.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.0171 - val_precision: 0.0171 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.0171\n",
      "Epoch 48/50\n",
      "10590/10590 [==============================] - 12s 1ms/step - loss: 0.7718 - tp: 11093.0000 - fp: 666634.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 0.0164 - precision: 0.0164 - recall: 1.0000 - auc: 0.4963 - prc: 0.0161 - val_loss: 0.8036 - val_tp: 1449.0000 - val_fp: 83266.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.0171 - val_precision: 0.0171 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.0171\n",
      "Epoch 49/50\n",
      "10590/10590 [==============================] - 12s 1ms/step - loss: 0.7717 - tp: 11093.0000 - fp: 666634.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 0.0164 - precision: 0.0164 - recall: 1.0000 - auc: 0.4968 - prc: 0.0162 - val_loss: 0.7794 - val_tp: 1449.0000 - val_fp: 83266.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.0171 - val_precision: 0.0171 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.0171\n",
      "Epoch 50/50\n",
      "10590/10590 [==============================] - 12s 1ms/step - loss: 0.7716 - tp: 11093.0000 - fp: 666634.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 0.0164 - precision: 0.0164 - recall: 1.0000 - auc: 0.5038 - prc: 0.0165 - val_loss: 0.7567 - val_tp: 1449.0000 - val_fp: 83266.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.0171 - val_precision: 0.0171 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.0171\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, Y_train, epochs=50, batch_size=64, validation_data=(X_val, Y_val), class_weight=class_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_metrics(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss :  [0.53179353]\n",
      "tp :  [0.53179353]\n",
      "fp :  [0.53179353]\n",
      "tn :  [0.53179353]\n",
      "fn :  [0.53179353]\n",
      "accuracy :  [0.53179353]\n",
      "precision :  [0.53179353]\n",
      "recall :  [0.53179353]\n",
      "auc :  [0.53179353]\n",
      "prc :  [0.53179353]\n",
      "\n",
      "====Wickets only====\n",
      "loss :  [0.53179353]\n",
      "tp :  [0.53179353]\n",
      "fp :  [0.53179353]\n",
      "tn :  [0.53179353]\n",
      "fn :  [0.53179353]\n",
      "accuracy :  [0.53179353]\n",
      "precision :  [0.53179353]\n",
      "recall :  [0.53179353]\n",
      "auc :  [0.53179353]\n",
      "prc :  [0.53179353]\n",
      "\n",
      "====NOs only====\n",
      "loss :  [0.53179353]\n",
      "tp :  [0.53179353]\n",
      "fp :  [0.53179353]\n",
      "tn :  [0.53179353]\n",
      "fn :  [0.53179353]\n",
      "accuracy :  [0.53179353]\n",
      "precision :  [0.53179353]\n",
      "recall :  [0.53179353]\n",
      "auc :  [0.53179353]\n",
      "prc :  [0.53179353]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_preds = model.predict(X_test, batch_size=2048)\n",
    "\n",
    "test_W = model.predict(X_test[(Y_test == 1).reshape((X_test.shape[0],))], batch_size=2048)\n",
    "test_no = model.predict(X_test[(Y_test == 0).reshape((X_test.shape[0],))], batch_size=2048)\n",
    "\n",
    "for name, value in zip(model.metrics_names, test_preds):\n",
    "  print(name, ': ', value)\n",
    "print()\n",
    "\n",
    "print(\"====Wickets only====\")\n",
    "for name, value in zip(model.metrics_names, test_W):\n",
    "  print(name, ': ', value)\n",
    "print()\n",
    "\n",
    "print(\"====NOs only====\")\n",
    "for name, value in zip(model.metrics_names, test_no):\n",
    "  print(name, ': ', value)\n",
    "print()\n",
    "\n",
    "#plot_roc(\"Test Baseline\", Y_test, test_preds)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
